{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 7,\n",
       " 'know': 1,\n",
       " 'want': 5,\n",
       " 'your': 8,\n",
       " 'love': 3,\n",
       " 'like': 2,\n",
       " 'what': 6,\n",
       " 'should': 4,\n",
       " 'do': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tv.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46735098, 0.        , 0.46735098, 0.        ,\n",
       "        0.46735098, 0.        , 0.35543247, 0.46735098],\n",
       "       [0.        , 0.        , 0.79596054, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.60534851, 0.        ],\n",
       "       [0.57735027, 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.57735027, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54522682, 0.14041576, 0.        , 0.14041576, 0.        ,\n",
       "        0.10904536, 0.14041576, 0.10904536, 0.3692597 , 0.43618145,\n",
       "        0.18462985, 0.        , 0.14041576, 0.21809073, 0.18462985,\n",
       "        0.28083152, 0.28083152],\n",
       "       [0.50040087, 0.        , 0.        , 0.32217861, 0.        ,\n",
       "        0.50040087, 0.32217861, 0.25020043, 0.        , 0.25020043,\n",
       "        0.        , 0.        , 0.        , 0.25020043, 0.        ,\n",
       "        0.        , 0.32217861],\n",
       "       [0.54546812, 0.17559738, 0.4617789 , 0.        , 0.4617789 ,\n",
       "        0.13636703, 0.        , 0.13636703, 0.        , 0.27273406,\n",
       "        0.        , 0.23088945, 0.17559738, 0.13636703, 0.        ,\n",
       "        0.17559738, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(analyzer='char')\n",
    "tv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(min_df=2)\n",
    "tv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.34142622, 0.34142622, 0.        , 0.        ,\n",
       "        0.34142622, 0.        , 0.        , 0.34142622, 0.34142622,\n",
       "        0.        , 0.        , 0.25966344, 0.34142622, 0.34142622,\n",
       "        0.34142622],\n",
       "       [0.        , 0.        , 0.        , 0.62276601, 0.62276601,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4736296 , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.4472136 , 0.        , 0.        ,\n",
       "        0.4472136 , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(ngram_range=(1,2))\n",
    "tv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "doc1 = np.array([2,3,0,1])\n",
    "doc2 = np.array([1,2,3,1])\n",
    "doc3 = np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docInput = np.array([1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문서와 [2 3 0 1] 사이 거리 :  2.23606797749979\n",
      "입력 문서와 [1 2 3 1] 사이 거리 :  3.1622776601683795\n",
      "입력 문서와 [2 1 2 2] 사이 거리 :  2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "docs = [doc1,doc2,doc3]\n",
    "\n",
    "for doc in docs:\n",
    "    dist = np.sqrt(np.square(np.abs(docInput - doc)).sum())\n",
    "    print(f'입력 문서와 {doc} 사이 거리 : ',dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__자카드 유사도?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J(문서1,문서2) = (doc1 ∩ doc2) / (doc1 + doc2)  \n",
    "- 교집합을 합집합으로 나누는 알고리즘  \n",
    "- 합집합에서 교집합의 비율을 유사도로 사용  \n",
    "- 0< J < 1 의 값 범위  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'apple banana everyone like likey watch card holder'\n",
    "doc2 = 'apple banana coupon passport love you'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok1 = doc1.split()\n",
    "tok2 = doc2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['likey',\n",
       " 'coupon',\n",
       " 'card',\n",
       " 'like',\n",
       " 'passport',\n",
       " 'holder',\n",
       " 'everyone',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'watch',\n",
       " 'love',\n",
       " 'you']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hab = list(set(tok1)|set(tok2)) # 합집합\n",
    "hab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyo = list(set(tok1)&set(tok2)) # 교집합\n",
    "gyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = len(gyo)/len(hab)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문서와 [2 3 0 1] 코사인 유사도 :  [0.9258201]\n",
      "입력 문서와 [1 2 3 1] 코사인 유사도 :  [0.59628479]\n",
      "입력 문서와 [2 1 2 2] 코사인 유사도 :  [0.80064077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc1 = np.array([2,3,0,1])\n",
    "doc2 = np.array([1,2,3,1])\n",
    "doc3 = np.array([2,1,2,2])\n",
    "\n",
    "docInput = np.array([1,1,0,1])\n",
    "\n",
    "docs = [doc1,doc2,doc3]\n",
    "\n",
    "for doc in docs:\n",
    "    cos_sim = cosine_similarity(docInput.reshape(1,-1),doc.reshape(1,-1))\n",
    "    print(f'입력 문서와 {doc} 코사인 유사도 : ',cos_sim[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "](https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    ")  \n",
    "실전!  \n",
    "- 4.5 만 이상의 영화 메타 정보 텍스트를 처리해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 대용량 파일을 다룰때는 low_memory 옵션 끄기\n",
    "movie_meta = pd.read_csv('C:/임시\\RData/movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "\n",
       "                               homepage    id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
       "1                                   NaN  8844  tt0113497                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video vote_average  \\\n",
       "0                                        NaN  Toy Story  False          7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
       "\n",
       "  vote_count  \n",
       "0     5415.0  \n",
       "1     2413.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Led by Woody, Andy's toys live happily in his ...\n",
       "1    When siblings Judy and Peter discover an encha...\n",
       "2    A family wedding reignites the ancient feud be...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_meta['overview'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__줄거리 기준으로 영화간 유사도 모델링__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 대용량 파일을 다룰때는 low_memory 옵션 끄기\n",
    "data = pd.read_csv('C:/임시\\RData/movies_metadata.csv', low_memory=False)\n",
    "data = data.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overview'] = data['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 47487)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfMat = TfidfVectorizer(stop_words='english')\n",
    "tfidfMat=tfidfMat.fit_transform(data['overview'])\n",
    "tfidfMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5036643709879097\n"
     ]
    }
   ],
   "source": [
    "print(np.max(tfidfMat[0].toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 단어 :  buzz\n"
     ]
    }
   ],
   "source": [
    "# 퀴즈 2 , 0.5036... 에 해당되는 단어 출력\n",
    "\n",
    "word_index_dict = TfidfVectorizer(stop_words='english').fit(data['overview']).vocabulary_\n",
    "index_word_dict = sorted(word_index_dict.items(),key=lambda x:x[1])\n",
    "\n",
    "idx = np.argmax(tfidfMat[0].toarray()[0])\n",
    "print(f'해당 단어 : ',index_word_dict[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cos_sim = linear_kernel(tfidfMat,tfidfMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Toy Story                                                                       0\n",
       "Jumanji                                                                         1\n",
       "Grumpier Old Men                                                                2\n",
       "Waiting to Exhale                                                               3\n",
       "Father of the Bride Part II                                                     4\n",
       "                                                                            ...  \n",
       "Rebellion                                                                   19995\n",
       "Versailles                                                                  19996\n",
       "Two in the Wave                                                             19997\n",
       "Lotte Reiniger: Homage to the Inventor of the Silhouette Film               19998\n",
       "RKO Production 601: The Making of 'Kong, the Eighth Wonder of the World'    19999\n",
       "Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = pd.Series(data.index,index=data.title).drop_duplicates()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices['Jumanji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumanji 와 가장 유사한 줄거리의 영화 TOP 20 : \n",
      "6166                       Brainscan\n",
      "8801                         Quintet\n",
      "17223                 The Dark Angel\n",
      "9503                       Word Wars\n",
      "13601    The Mindscape of Alan Moore\n",
      "16843                         DeVour\n",
      "8079                         Masques\n",
      "6055                Poolhall Junkies\n",
      "19726                 Wreck-It Ralph\n",
      "2486                        eXistenZ\n",
      "10892                     Stay Alive\n",
      "13711                     Rhinoceros\n",
      "1506              The Innocent Sleep\n",
      "9107                         Nirvana\n",
      "19345                       The Wave\n",
      "10703                  Grandma's Boy\n",
      "7749              The Last of Sheila\n",
      "14166                          Gamer\n",
      "12726           Battlefield Baseball\n",
      "15512                Le Pont du Nord\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 주만지 영화와 줄거리 코사인 유사도가 가장 높은 \n",
    "# 20편의 영화제목을 내림차순으로 출력하고자 한다.\n",
    "\n",
    "title_in = 'Jumanji'\n",
    "\n",
    "indices = pd.Series(data.index,index=data.title).drop_duplicates()\n",
    "cos_sim = linear_kernel(tfidfMat,tfidfMat)\n",
    "\n",
    "\n",
    "top20_idx = pd.Series(cos_sim[indices[title_in]]).sort_values(ascending=False)[1:21].index\n",
    "\n",
    "print(f'{title_in} 와 가장 유사한 줄거리의 영화 TOP 20 : ')\n",
    "print(data.title[top20_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
