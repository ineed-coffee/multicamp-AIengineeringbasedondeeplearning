{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28 , activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2.2394 - accuracy: 0.1486 - val_loss: 2.1510 - val_accuracy: 0.1667\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1177 - accuracy: 0.1500 - val_loss: 2.0648 - val_accuracy: 0.1533\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0339 - accuracy: 0.1900 - val_loss: 2.0025 - val_accuracy: 0.2400\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s 1000us/step - loss: 1.9631 - accuracy: 0.2329 - val_loss: 1.9474 - val_accuracy: 0.2500\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8990 - accuracy: 0.2243 - val_loss: 1.8965 - val_accuracy: 0.2300\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8361 - accuracy: 0.3057 - val_loss: 1.8498 - val_accuracy: 0.3133\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7758 - accuracy: 0.3771 - val_loss: 1.8036 - val_accuracy: 0.3567\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7249 - accuracy: 0.3886 - val_loss: 1.7717 - val_accuracy: 0.3500\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6784 - accuracy: 0.3914 - val_loss: 1.7379 - val_accuracy: 0.3767\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6370 - accuracy: 0.4029 - val_loss: 1.7107 - val_accuracy: 0.3767\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6009 - accuracy: 0.4129 - val_loss: 1.6875 - val_accuracy: 0.3833\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5681 - accuracy: 0.4243 - val_loss: 1.6684 - val_accuracy: 0.3900\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5393 - accuracy: 0.4371 - val_loss: 1.6551 - val_accuracy: 0.4100\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5137 - accuracy: 0.4543 - val_loss: 1.6337 - val_accuracy: 0.4033\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4851 - accuracy: 0.4700 - val_loss: 1.6192 - val_accuracy: 0.4067\n",
      "Epoch 16/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4596 - accuracy: 0.4771 - val_loss: 1.6013 - val_accuracy: 0.4300\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 1.4379 - accuracy: 0.4943 - val_loss: 1.5952 - val_accuracy: 0.4500\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4159 - accuracy: 0.4971 - val_loss: 1.5754 - val_accuracy: 0.4267\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3935 - accuracy: 0.5086 - val_loss: 1.5680 - val_accuracy: 0.4533\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3725 - accuracy: 0.5314 - val_loss: 1.5591 - val_accuracy: 0.4567\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3567 - accuracy: 0.5329 - val_loss: 1.5323 - val_accuracy: 0.4767\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3369 - accuracy: 0.5471 - val_loss: 1.5227 - val_accuracy: 0.4933\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3180 - accuracy: 0.5543 - val_loss: 1.5160 - val_accuracy: 0.4967\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3009 - accuracy: 0.5543 - val_loss: 1.5039 - val_accuracy: 0.5033\n",
      "Epoch 25/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2831 - accuracy: 0.5543 - val_loss: 1.4911 - val_accuracy: 0.5000\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2677 - accuracy: 0.5686 - val_loss: 1.4846 - val_accuracy: 0.5200\n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 1.2505 - accuracy: 0.5771 - val_loss: 1.4764 - val_accuracy: 0.5333\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2373 - accuracy: 0.5886 - val_loss: 1.4676 - val_accuracy: 0.5167\n",
      "Epoch 29/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2207 - accuracy: 0.5857 - val_loss: 1.4599 - val_accuracy: 0.5267\n",
      "Epoch 30/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2089 - accuracy: 0.5886 - val_loss: 1.4566 - val_accuracy: 0.5100\n",
      "Epoch 31/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1947 - accuracy: 0.5814 - val_loss: 1.4455 - val_accuracy: 0.5233\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1818 - accuracy: 0.6057 - val_loss: 1.4396 - val_accuracy: 0.5133\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1672 - accuracy: 0.6000 - val_loss: 1.4313 - val_accuracy: 0.5200\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1544 - accuracy: 0.6043 - val_loss: 1.4208 - val_accuracy: 0.5233\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1435 - accuracy: 0.6214 - val_loss: 1.4168 - val_accuracy: 0.5400\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1367 - accuracy: 0.6043 - val_loss: 1.4103 - val_accuracy: 0.5200\n",
      "Epoch 37/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1202 - accuracy: 0.6257 - val_loss: 1.4221 - val_accuracy: 0.5100\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1095 - accuracy: 0.6286 - val_loss: 1.4043 - val_accuracy: 0.5400\n",
      "Epoch 39/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 1.0994 - accuracy: 0.6186 - val_loss: 1.3982 - val_accuracy: 0.5400\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0880 - accuracy: 0.6486 - val_loss: 1.4036 - val_accuracy: 0.5133\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0782 - accuracy: 0.6543 - val_loss: 1.3962 - val_accuracy: 0.5367\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0686 - accuracy: 0.6614 - val_loss: 1.3989 - val_accuracy: 0.5400\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0596 - accuracy: 0.6614 - val_loss: 1.4026 - val_accuracy: 0.5367\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0507 - accuracy: 0.6500 - val_loss: 1.3976 - val_accuracy: 0.5267\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0444 - accuracy: 0.6543 - val_loss: 1.3970 - val_accuracy: 0.5400\n",
      "Epoch 46/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0342 - accuracy: 0.6543 - val_loss: 1.3881 - val_accuracy: 0.5467\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.6543 - val_loss: 1.3955 - val_accuracy: 0.5300\n",
      "Epoch 48/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0183 - accuracy: 0.6657 - val_loss: 1.3867 - val_accuracy: 0.5400\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.6671 - val_loss: 1.3908 - val_accuracy: 0.5367\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0063 - accuracy: 0.6643 - val_loss: 1.3826 - val_accuracy: 0.5467\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9972 - accuracy: 0.6743 - val_loss: 1.3832 - val_accuracy: 0.5333\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9929 - accuracy: 0.6700 - val_loss: 1.3935 - val_accuracy: 0.5400\n",
      "Epoch 53/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9855 - accuracy: 0.6729 - val_loss: 1.3881 - val_accuracy: 0.5433\n",
      "Epoch 54/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9785 - accuracy: 0.6771 - val_loss: 1.3969 - val_accuracy: 0.5267\n",
      "Epoch 55/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.6700 - val_loss: 1.3877 - val_accuracy: 0.5433\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9650 - accuracy: 0.6786 - val_loss: 1.3913 - val_accuracy: 0.5433\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9598 - accuracy: 0.6857 - val_loss: 1.3975 - val_accuracy: 0.5267\n",
      "Epoch 58/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9545 - accuracy: 0.6814 - val_loss: 1.3858 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9484 - accuracy: 0.6886 - val_loss: 1.3970 - val_accuracy: 0.5333\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9421 - accuracy: 0.6886 - val_loss: 1.3869 - val_accuracy: 0.5433\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9405 - accuracy: 0.6886 - val_loss: 1.4157 - val_accuracy: 0.5300\n",
      "Epoch 62/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9338 - accuracy: 0.6971 - val_loss: 1.4008 - val_accuracy: 0.5133\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9263 - accuracy: 0.6929 - val_loss: 1.3979 - val_accuracy: 0.5233\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s 943us/step - loss: 0.9228 - accuracy: 0.6857 - val_loss: 1.4107 - val_accuracy: 0.5333\n",
      "Epoch 65/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9165 - accuracy: 0.6957 - val_loss: 1.4010 - val_accuracy: 0.5333\n",
      "Epoch 66/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9113 - accuracy: 0.7000 - val_loss: 1.4123 - val_accuracy: 0.5333\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.6957 - val_loss: 1.3980 - val_accuracy: 0.5267\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9013 - accuracy: 0.7014 - val_loss: 1.4096 - val_accuracy: 0.5300\n",
      "Epoch 69/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.7057 - val_loss: 1.4028 - val_accuracy: 0.5267\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.7000 - val_loss: 1.4226 - val_accuracy: 0.5233\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.7057 - val_loss: 1.4158 - val_accuracy: 0.5300\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.7086 - val_loss: 1.4275 - val_accuracy: 0.5267\n",
      "Epoch 73/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8782 - accuracy: 0.7043 - val_loss: 1.4161 - val_accuracy: 0.5267\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s 943us/step - loss: 0.8752 - accuracy: 0.7057 - val_loss: 1.4218 - val_accuracy: 0.5333\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8705 - accuracy: 0.7157 - val_loss: 1.4112 - val_accuracy: 0.5300\n",
      "Epoch 76/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8671 - accuracy: 0.7143 - val_loss: 1.4316 - val_accuracy: 0.5300\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8638 - accuracy: 0.7143 - val_loss: 1.4150 - val_accuracy: 0.5200\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8583 - accuracy: 0.7114 - val_loss: 1.4345 - val_accuracy: 0.5300\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8543 - accuracy: 0.7129 - val_loss: 1.4360 - val_accuracy: 0.5267\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.7171 - val_loss: 1.4467 - val_accuracy: 0.5300\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8483 - accuracy: 0.7129 - val_loss: 1.4437 - val_accuracy: 0.5400\n",
      "Epoch 82/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8428 - accuracy: 0.7157 - val_loss: 1.4319 - val_accuracy: 0.5300\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8398 - accuracy: 0.7171 - val_loss: 1.4371 - val_accuracy: 0.5300\n",
      "Epoch 84/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.8368 - accuracy: 0.7257 - val_loss: 1.4600 - val_accuracy: 0.5333\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8340 - accuracy: 0.7214 - val_loss: 1.4550 - val_accuracy: 0.5300\n",
      "Epoch 86/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8282 - accuracy: 0.7229 - val_loss: 1.4363 - val_accuracy: 0.5300\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8258 - accuracy: 0.7186 - val_loss: 1.4346 - val_accuracy: 0.5300\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8191 - accuracy: 0.7286 - val_loss: 1.5132 - val_accuracy: 0.5233\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8209 - accuracy: 0.7271 - val_loss: 1.4479 - val_accuracy: 0.5367\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8146 - accuracy: 0.7357 - val_loss: 1.4708 - val_accuracy: 0.5400\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.8136 - accuracy: 0.7171 - val_loss: 1.4653 - val_accuracy: 0.5367\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8074 - accuracy: 0.7314 - val_loss: 1.4653 - val_accuracy: 0.5333\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8065 - accuracy: 0.7286 - val_loss: 1.4829 - val_accuracy: 0.5400\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8021 - accuracy: 0.7329 - val_loss: 1.4677 - val_accuracy: 0.5367\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7992 - accuracy: 0.7357 - val_loss: 1.4954 - val_accuracy: 0.5333\n",
      "Epoch 96/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7962 - accuracy: 0.7371 - val_loss: 1.4965 - val_accuracy: 0.5367\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7935 - accuracy: 0.7357 - val_loss: 1.4984 - val_accuracy: 0.5333\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7920 - accuracy: 0.7329 - val_loss: 1.4910 - val_accuracy: 0.5467\n",
      "Epoch 99/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.7429 - val_loss: 1.5001 - val_accuracy: 0.5500\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7827 - accuracy: 0.7443 - val_loss: 1.4871 - val_accuracy: 0.5433\n",
      "Epoch 101/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7784 - accuracy: 0.7471 - val_loss: 1.4998 - val_accuracy: 0.5433\n",
      "Epoch 102/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7748 - accuracy: 0.7429 - val_loss: 1.5237 - val_accuracy: 0.5367\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.7752 - accuracy: 0.7457 - val_loss: 1.5069 - val_accuracy: 0.5333\n",
      "Epoch 104/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7700 - accuracy: 0.7429 - val_loss: 1.5061 - val_accuracy: 0.5367\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7671 - accuracy: 0.7414 - val_loss: 1.5130 - val_accuracy: 0.5433\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7641 - accuracy: 0.7400 - val_loss: 1.4985 - val_accuracy: 0.5467\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7624 - accuracy: 0.7457 - val_loss: 1.5153 - val_accuracy: 0.5433\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7581 - accuracy: 0.7471 - val_loss: 1.5205 - val_accuracy: 0.5367\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7566 - accuracy: 0.7429 - val_loss: 1.5298 - val_accuracy: 0.5367\n",
      "Epoch 110/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7545 - accuracy: 0.7500 - val_loss: 1.4971 - val_accuracy: 0.5467\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7515 - accuracy: 0.7500 - val_loss: 1.5037 - val_accuracy: 0.5467\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7463 - accuracy: 0.7486 - val_loss: 1.5269 - val_accuracy: 0.5467\n",
      "Epoch 113/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.7460 - accuracy: 0.7543 - val_loss: 1.5233 - val_accuracy: 0.5467\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7401 - accuracy: 0.7557 - val_loss: 1.5626 - val_accuracy: 0.5400\n",
      "Epoch 115/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.7571 - val_loss: 1.5294 - val_accuracy: 0.5400\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.7543 - val_loss: 1.5729 - val_accuracy: 0.5367\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.7571 - val_loss: 1.5326 - val_accuracy: 0.5433\n",
      "Epoch 118/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.7686 - val_loss: 1.5292 - val_accuracy: 0.5533\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.7629 - val_loss: 1.5463 - val_accuracy: 0.5367\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s 929us/step - loss: 0.7263 - accuracy: 0.7657 - val_loss: 1.5877 - val_accuracy: 0.5433\n",
      "Epoch 121/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.7686 - val_loss: 1.5725 - val_accuracy: 0.5367\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.7657 - val_loss: 1.5577 - val_accuracy: 0.5367\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.7686 - val_loss: 1.5780 - val_accuracy: 0.5400\n",
      "Epoch 124/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.7757 - val_loss: 1.5607 - val_accuracy: 0.5400\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.7124 - accuracy: 0.7743 - val_loss: 1.5626 - val_accuracy: 0.5500\n",
      "Epoch 126/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7128 - accuracy: 0.7671 - val_loss: 1.5916 - val_accuracy: 0.5433\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.7729 - val_loss: 1.5825 - val_accuracy: 0.5400\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.7743 - val_loss: 1.5945 - val_accuracy: 0.5400\n",
      "Epoch 129/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.7771 - val_loss: 1.6105 - val_accuracy: 0.5433\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.7786 - val_loss: 1.6005 - val_accuracy: 0.5433\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6996 - accuracy: 0.7800 - val_loss: 1.6196 - val_accuracy: 0.5500\n",
      "Epoch 132/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.6984 - accuracy: 0.7786 - val_loss: 1.5935 - val_accuracy: 0.5467\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.7843 - val_loss: 1.6051 - val_accuracy: 0.5467\n",
      "Epoch 134/300\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.6932 - accuracy: 0.7829 - val_loss: 1.6112 - val_accuracy: 0.5433\n",
      "Epoch 135/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.7829 - val_loss: 1.6182 - val_accuracy: 0.5467\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.7786 - val_loss: 1.6489 - val_accuracy: 0.5433\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.7829 - val_loss: 1.6288 - val_accuracy: 0.5467\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.7814 - val_loss: 1.6425 - val_accuracy: 0.5533\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.7843 - val_loss: 1.6440 - val_accuracy: 0.5533\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.6806 - accuracy: 0.7857 - val_loss: 1.6464 - val_accuracy: 0.5533\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.7900 - val_loss: 1.6803 - val_accuracy: 0.5433\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.7786 - val_loss: 1.6557 - val_accuracy: 0.5433\n",
      "Epoch 143/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.7871 - val_loss: 1.6712 - val_accuracy: 0.5500\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.7843 - val_loss: 1.6895 - val_accuracy: 0.5500\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.6703 - accuracy: 0.7871 - val_loss: 1.6986 - val_accuracy: 0.5433\n",
      "Epoch 146/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.7886 - val_loss: 1.6716 - val_accuracy: 0.5433\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.7943 - val_loss: 1.6991 - val_accuracy: 0.5500\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.7900 - val_loss: 1.6814 - val_accuracy: 0.5533\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.7914 - val_loss: 1.6833 - val_accuracy: 0.5500\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.7957 - val_loss: 1.6971 - val_accuracy: 0.5467\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.7957 - val_loss: 1.6967 - val_accuracy: 0.5533\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.8029 - val_loss: 1.7169 - val_accuracy: 0.5467\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.8014 - val_loss: 1.7141 - val_accuracy: 0.5567\n",
      "Epoch 154/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.8014 - val_loss: 1.6785 - val_accuracy: 0.5233\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.8014 - val_loss: 1.7294 - val_accuracy: 0.5567\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.6477 - accuracy: 0.8043 - val_loss: 1.7280 - val_accuracy: 0.5467\n",
      "Epoch 157/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.8057 - val_loss: 1.7369 - val_accuracy: 0.5567\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.8029 - val_loss: 1.7309 - val_accuracy: 0.5500\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.8057 - val_loss: 1.7416 - val_accuracy: 0.5567\n",
      "Epoch 160/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.8086 - val_loss: 1.7483 - val_accuracy: 0.5533\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.8029 - val_loss: 1.7455 - val_accuracy: 0.5567\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.8086 - val_loss: 1.7541 - val_accuracy: 0.5500\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.6357 - accuracy: 0.8086 - val_loss: 1.7870 - val_accuracy: 0.5500\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.8071 - val_loss: 1.7635 - val_accuracy: 0.5567\n",
      "Epoch 165/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.8129 - val_loss: 1.7479 - val_accuracy: 0.5567\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.8129 - val_loss: 1.8164 - val_accuracy: 0.5400\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.8029 - val_loss: 1.7640 - val_accuracy: 0.5533\n",
      "Epoch 168/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.8086 - val_loss: 1.7778 - val_accuracy: 0.5500\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6260 - accuracy: 0.8186 - val_loss: 1.7839 - val_accuracy: 0.5467\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.6251 - accuracy: 0.8114 - val_loss: 1.8345 - val_accuracy: 0.5467\n",
      "Epoch 171/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.8071 - val_loss: 1.8145 - val_accuracy: 0.5433\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.8071 - val_loss: 1.8024 - val_accuracy: 0.5467\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.8129 - val_loss: 1.8169 - val_accuracy: 0.5533\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.8171 - val_loss: 1.8272 - val_accuracy: 0.5467\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.8171 - val_loss: 1.8247 - val_accuracy: 0.5400\n",
      "Epoch 176/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.8114 - val_loss: 1.8433 - val_accuracy: 0.5367\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.8143 - val_loss: 1.8462 - val_accuracy: 0.5500\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.8171 - val_loss: 1.8285 - val_accuracy: 0.5567\n",
      "Epoch 179/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.8200 - val_loss: 1.8555 - val_accuracy: 0.5500\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.8171 - val_loss: 1.8460 - val_accuracy: 0.5500\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.8157 - val_loss: 1.8577 - val_accuracy: 0.5533\n",
      "Epoch 182/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.8200 - val_loss: 1.8832 - val_accuracy: 0.5467\n",
      "Epoch 183/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.8186 - val_loss: 1.8494 - val_accuracy: 0.5533\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.6019 - accuracy: 0.8214 - val_loss: 1.8758 - val_accuracy: 0.5533\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.6021 - accuracy: 0.8214 - val_loss: 1.8680 - val_accuracy: 0.5400\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5990 - accuracy: 0.8200 - val_loss: 1.9165 - val_accuracy: 0.5367\n",
      "Epoch 187/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.8214 - val_loss: 1.8948 - val_accuracy: 0.5500\n",
      "Epoch 188/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.8271 - val_loss: 1.8793 - val_accuracy: 0.5400\n",
      "Epoch 189/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.5960 - accuracy: 0.8171 - val_loss: 1.9254 - val_accuracy: 0.5300\n",
      "Epoch 190/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.8286 - val_loss: 1.9259 - val_accuracy: 0.5500\n",
      "Epoch 191/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.8243 - val_loss: 1.9202 - val_accuracy: 0.5433\n",
      "Epoch 192/300\n",
      "70/70 [==============================] - 0s 943us/step - loss: 0.5908 - accuracy: 0.8243 - val_loss: 1.9046 - val_accuracy: 0.5400\n",
      "Epoch 193/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.8257 - val_loss: 1.9400 - val_accuracy: 0.5400\n",
      "Epoch 194/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.5878 - accuracy: 0.8300 - val_loss: 1.9295 - val_accuracy: 0.5400\n",
      "Epoch 195/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.8186 - val_loss: 1.9425 - val_accuracy: 0.5433\n",
      "Epoch 196/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.8271 - val_loss: 1.9222 - val_accuracy: 0.5367\n",
      "Epoch 197/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.8229 - val_loss: 1.9348 - val_accuracy: 0.5400\n",
      "Epoch 198/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5828 - accuracy: 0.8329 - val_loss: 1.9584 - val_accuracy: 0.5367\n",
      "Epoch 199/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.8257 - val_loss: 1.9726 - val_accuracy: 0.5400\n",
      "Epoch 200/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.5804 - accuracy: 0.8271 - val_loss: 1.9884 - val_accuracy: 0.5433\n",
      "Epoch 201/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.8271 - val_loss: 1.9289 - val_accuracy: 0.5367\n",
      "Epoch 202/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.8257 - val_loss: 1.9996 - val_accuracy: 0.5433\n",
      "Epoch 203/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.8229 - val_loss: 1.9687 - val_accuracy: 0.5333\n",
      "Epoch 204/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.5740 - accuracy: 0.8286 - val_loss: 2.0057 - val_accuracy: 0.5433\n",
      "Epoch 205/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.8343 - val_loss: 1.9930 - val_accuracy: 0.5367\n",
      "Epoch 206/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.8286 - val_loss: 2.0122 - val_accuracy: 0.5433\n",
      "Epoch 207/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.8329 - val_loss: 2.0136 - val_accuracy: 0.5367\n",
      "Epoch 208/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.8329 - val_loss: 2.0025 - val_accuracy: 0.5300\n",
      "Epoch 209/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.5683 - accuracy: 0.8314 - val_loss: 2.0092 - val_accuracy: 0.5433\n",
      "Epoch 210/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.8300 - val_loss: 2.0166 - val_accuracy: 0.5333\n",
      "Epoch 211/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.8271 - val_loss: 2.0431 - val_accuracy: 0.5367\n",
      "Epoch 212/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.8343 - val_loss: 2.0267 - val_accuracy: 0.5367\n",
      "Epoch 213/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.8329 - val_loss: 2.0205 - val_accuracy: 0.5400\n",
      "Epoch 214/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.5625 - accuracy: 0.8343 - val_loss: 2.0509 - val_accuracy: 0.5367\n",
      "Epoch 215/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.8300 - val_loss: 2.0583 - val_accuracy: 0.5367\n",
      "Epoch 216/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.8343 - val_loss: 2.0573 - val_accuracy: 0.5400\n",
      "Epoch 217/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.8357 - val_loss: 2.0632 - val_accuracy: 0.5367\n",
      "Epoch 218/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.8357 - val_loss: 2.0480 - val_accuracy: 0.5300\n",
      "Epoch 219/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.8371 - val_loss: 2.0810 - val_accuracy: 0.5367\n",
      "Epoch 220/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.8386 - val_loss: 2.0888 - val_accuracy: 0.5367\n",
      "Epoch 221/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.8357 - val_loss: 2.0708 - val_accuracy: 0.5333\n",
      "Epoch 222/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.8343 - val_loss: 2.0842 - val_accuracy: 0.5367\n",
      "Epoch 223/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.8371 - val_loss: 2.0983 - val_accuracy: 0.5367\n",
      "Epoch 224/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.8371 - val_loss: 2.1222 - val_accuracy: 0.5300\n",
      "Epoch 225/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.8429 - val_loss: 2.0992 - val_accuracy: 0.5333\n",
      "Epoch 226/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.8371 - val_loss: 2.1313 - val_accuracy: 0.5333\n",
      "Epoch 227/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.8343 - val_loss: 2.1152 - val_accuracy: 0.5300\n",
      "Epoch 228/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.8414 - val_loss: 2.1254 - val_accuracy: 0.5333\n",
      "Epoch 229/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.5417 - accuracy: 0.8414 - val_loss: 2.1546 - val_accuracy: 0.5200\n",
      "Epoch 230/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.8371 - val_loss: 2.1022 - val_accuracy: 0.5267\n",
      "Epoch 231/300\n",
      "70/70 [==============================] - 0s 943us/step - loss: 0.5403 - accuracy: 0.8386 - val_loss: 2.1560 - val_accuracy: 0.5300\n",
      "Epoch 232/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.8386 - val_loss: 2.1169 - val_accuracy: 0.5300\n",
      "Epoch 233/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.8414 - val_loss: 2.1338 - val_accuracy: 0.5233\n",
      "Epoch 234/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.8386 - val_loss: 2.1517 - val_accuracy: 0.5267\n",
      "Epoch 235/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.8414 - val_loss: 2.1388 - val_accuracy: 0.5300\n",
      "Epoch 236/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.8371 - val_loss: 2.1722 - val_accuracy: 0.5367\n",
      "Epoch 237/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.8414 - val_loss: 2.2072 - val_accuracy: 0.5300\n",
      "Epoch 238/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.8414 - val_loss: 2.1706 - val_accuracy: 0.5233\n",
      "Epoch 239/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.8443 - val_loss: 2.1973 - val_accuracy: 0.5333\n",
      "Epoch 240/300\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.5284 - accuracy: 0.8429 - val_loss: 2.1741 - val_accuracy: 0.5233\n",
      "Epoch 241/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.8443 - val_loss: 2.2208 - val_accuracy: 0.5233\n",
      "Epoch 242/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.8471 - val_loss: 2.2150 - val_accuracy: 0.5267\n",
      "Epoch 243/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.8414 - val_loss: 2.2063 - val_accuracy: 0.5433\n",
      "Epoch 244/300\n",
      "70/70 [==============================] - 0s 943us/step - loss: 0.5255 - accuracy: 0.8429 - val_loss: 2.2241 - val_accuracy: 0.5233\n",
      "Epoch 245/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.8457 - val_loss: 2.2295 - val_accuracy: 0.5267\n",
      "Epoch 246/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.8429 - val_loss: 2.2356 - val_accuracy: 0.5233\n",
      "Epoch 247/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.8471 - val_loss: 2.2518 - val_accuracy: 0.5233\n",
      "Epoch 248/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.8457 - val_loss: 2.2579 - val_accuracy: 0.5233\n",
      "Epoch 249/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.8400 - val_loss: 2.2142 - val_accuracy: 0.5300\n",
      "Epoch 250/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.8443 - val_loss: 2.2573 - val_accuracy: 0.5367\n",
      "Epoch 251/300\n",
      "70/70 [==============================] - 0s 929us/step - loss: 0.5186 - accuracy: 0.8457 - val_loss: 2.2768 - val_accuracy: 0.5267\n",
      "Epoch 252/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.8500 - val_loss: 2.2536 - val_accuracy: 0.5300\n",
      "Epoch 253/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8443 - val_loss: 2.2690 - val_accuracy: 0.5333\n",
      "Epoch 254/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.8471 - val_loss: 2.2866 - val_accuracy: 0.5200\n",
      "Epoch 255/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.5156 - accuracy: 0.8443 - val_loss: 2.2856 - val_accuracy: 0.5233\n",
      "Epoch 256/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8443 - val_loss: 2.2833 - val_accuracy: 0.5267\n",
      "Epoch 257/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.8471 - val_loss: 2.3040 - val_accuracy: 0.5233\n",
      "Epoch 258/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.8471 - val_loss: 2.3033 - val_accuracy: 0.5233\n",
      "Epoch 259/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.8486 - val_loss: 2.3064 - val_accuracy: 0.5133\n",
      "Epoch 260/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.8457 - val_loss: 2.3476 - val_accuracy: 0.5233\n",
      "Epoch 261/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8500 - val_loss: 2.3200 - val_accuracy: 0.5233\n",
      "Epoch 262/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.8471 - val_loss: 2.3364 - val_accuracy: 0.5167\n",
      "Epoch 263/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8486 - val_loss: 2.3349 - val_accuracy: 0.5300\n",
      "Epoch 264/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8471 - val_loss: 2.3393 - val_accuracy: 0.5200\n",
      "Epoch 265/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8471 - val_loss: 2.3307 - val_accuracy: 0.5200\n",
      "Epoch 266/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8471 - val_loss: 2.3820 - val_accuracy: 0.5200\n",
      "Epoch 267/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8457 - val_loss: 2.3364 - val_accuracy: 0.5100\n",
      "Epoch 268/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8457 - val_loss: 2.3945 - val_accuracy: 0.5167\n",
      "Epoch 269/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8500 - val_loss: 2.3753 - val_accuracy: 0.5200\n",
      "Epoch 270/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8529 - val_loss: 2.3527 - val_accuracy: 0.5233\n",
      "Epoch 271/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8457 - val_loss: 2.3655 - val_accuracy: 0.5200\n",
      "Epoch 272/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8514 - val_loss: 2.3668 - val_accuracy: 0.5233\n",
      "Epoch 273/300\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.4964 - accuracy: 0.8514 - val_loss: 2.3934 - val_accuracy: 0.5233\n",
      "Epoch 274/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8514 - val_loss: 2.4009 - val_accuracy: 0.5167\n",
      "Epoch 275/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8514 - val_loss: 2.4088 - val_accuracy: 0.5233\n",
      "Epoch 276/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8500 - val_loss: 2.4221 - val_accuracy: 0.5233\n",
      "Epoch 277/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8514 - val_loss: 2.4321 - val_accuracy: 0.5200\n",
      "Epoch 278/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8557 - val_loss: 2.4433 - val_accuracy: 0.5233\n",
      "Epoch 279/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8486 - val_loss: 2.4063 - val_accuracy: 0.5300\n",
      "Epoch 280/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8543 - val_loss: 2.4232 - val_accuracy: 0.5267\n",
      "Epoch 281/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8500 - val_loss: 2.3835 - val_accuracy: 0.5167\n",
      "Epoch 282/300\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.4912 - accuracy: 0.8571 - val_loss: 2.4498 - val_accuracy: 0.5233\n",
      "Epoch 283/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8543 - val_loss: 2.4723 - val_accuracy: 0.5267\n",
      "Epoch 284/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8586 - val_loss: 2.4534 - val_accuracy: 0.5167\n",
      "Epoch 285/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8529 - val_loss: 2.4622 - val_accuracy: 0.5200\n",
      "Epoch 286/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.8500 - val_loss: 2.4687 - val_accuracy: 0.5200\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8557 - val_loss: 2.4526 - val_accuracy: 0.5233\n",
      "Epoch 288/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8571 - val_loss: 2.4756 - val_accuracy: 0.5167\n",
      "Epoch 289/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8529 - val_loss: 2.5201 - val_accuracy: 0.5200\n",
      "Epoch 290/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8543 - val_loss: 2.4916 - val_accuracy: 0.5267\n",
      "Epoch 291/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8543 - val_loss: 2.5060 - val_accuracy: 0.5133\n",
      "Epoch 292/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.8500 - val_loss: 2.4847 - val_accuracy: 0.5133\n",
      "Epoch 293/300\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.4808 - accuracy: 0.8529 - val_loss: 2.4767 - val_accuracy: 0.5100\n",
      "Epoch 294/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.8529 - val_loss: 2.5271 - val_accuracy: 0.5200\n",
      "Epoch 295/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8557 - val_loss: 2.5058 - val_accuracy: 0.5100\n",
      "Epoch 296/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8571 - val_loss: 2.5357 - val_accuracy: 0.5133\n",
      "Epoch 297/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8571 - val_loss: 2.5245 - val_accuracy: 0.5100\n",
      "Epoch 298/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8557 - val_loss: 2.6036 - val_accuracy: 0.5067\n",
      "Epoch 299/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8557 - val_loss: 2.5806 - val_accuracy: 0.5133\n",
      "Epoch 300/300\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8600 - val_loss: 2.5863 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs=300,batch_size=10,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 856us/step - loss: 2.4408 - accuracy: 0.5276\n",
      "\n",
      "loss : 2.440767288208008\n",
      "accuray : 0.5275999903678894\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Early Stopping__  \n",
    "- 콜백함수 (사용자가 설정한 환경이 되었을때 , 시스템에 의해 자동으로 호출되는 함수)  \n",
    "- monitor : 관찰항목 (val , loss , val_acc)  \n",
    "- min_delta : 변화량이 min_delta 보다 작으면 개선이 없다고 판단  \n",
    "- patience : 개선이 없으면 바로 학습을 중단하는 것이 아니라 patience 만큼의 epoch 동안 개선이 없으면 중단  \n",
    "- mode : 개선 확인을 위한 유형 min , auto 등의 유형 (min_delta 만큼 커져야하는지 작아져야하는지 같은)  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2.2120 - accuracy: 0.1829 - val_loss: 2.1743 - val_accuracy: 0.2300\n",
      "Epoch 2/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0742 - accuracy: 0.3043 - val_loss: 2.0960 - val_accuracy: 0.2633\n",
      "Epoch 3/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9878 - accuracy: 0.3257 - val_loss: 2.0478 - val_accuracy: 0.2767\n",
      "Epoch 4/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9242 - accuracy: 0.3471 - val_loss: 1.9997 - val_accuracy: 0.3067\n",
      "Epoch 5/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8730 - accuracy: 0.3729 - val_loss: 1.9491 - val_accuracy: 0.3300\n",
      "Epoch 6/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8239 - accuracy: 0.3886 - val_loss: 1.9199 - val_accuracy: 0.3200\n",
      "Epoch 7/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7847 - accuracy: 0.3914 - val_loss: 1.8900 - val_accuracy: 0.3267\n",
      "Epoch 8/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7452 - accuracy: 0.4129 - val_loss: 1.8465 - val_accuracy: 0.3400\n",
      "Epoch 9/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7102 - accuracy: 0.4043 - val_loss: 1.8216 - val_accuracy: 0.3300\n",
      "Epoch 10/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6743 - accuracy: 0.4129 - val_loss: 1.7940 - val_accuracy: 0.3500\n",
      "Epoch 11/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6467 - accuracy: 0.4271 - val_loss: 1.7825 - val_accuracy: 0.3300\n",
      "Epoch 12/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6177 - accuracy: 0.4300 - val_loss: 1.7367 - val_accuracy: 0.3600\n",
      "Epoch 13/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5855 - accuracy: 0.4200 - val_loss: 1.7056 - val_accuracy: 0.3633\n",
      "Epoch 14/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5588 - accuracy: 0.4443 - val_loss: 1.6848 - val_accuracy: 0.3533\n",
      "Epoch 15/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5337 - accuracy: 0.4486 - val_loss: 1.6662 - val_accuracy: 0.3700\n",
      "Epoch 16/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5078 - accuracy: 0.4557 - val_loss: 1.6424 - val_accuracy: 0.3800\n",
      "Epoch 17/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4844 - accuracy: 0.4643 - val_loss: 1.6198 - val_accuracy: 0.3900\n",
      "Epoch 18/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4631 - accuracy: 0.4800 - val_loss: 1.6015 - val_accuracy: 0.3933\n",
      "Epoch 19/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4432 - accuracy: 0.4957 - val_loss: 1.5942 - val_accuracy: 0.3933\n",
      "Epoch 20/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4193 - accuracy: 0.5014 - val_loss: 1.5767 - val_accuracy: 0.4100\n",
      "Epoch 21/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4008 - accuracy: 0.5029 - val_loss: 1.5686 - val_accuracy: 0.4033\n",
      "Epoch 22/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3792 - accuracy: 0.5129 - val_loss: 1.5395 - val_accuracy: 0.4233\n",
      "Epoch 23/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3597 - accuracy: 0.5171 - val_loss: 1.5192 - val_accuracy: 0.4167\n",
      "Epoch 24/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3425 - accuracy: 0.5200 - val_loss: 1.5279 - val_accuracy: 0.4233\n",
      "Epoch 25/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3229 - accuracy: 0.5329 - val_loss: 1.4896 - val_accuracy: 0.4233\n",
      "Epoch 26/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3022 - accuracy: 0.5400 - val_loss: 1.4950 - val_accuracy: 0.4533\n",
      "Epoch 27/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2877 - accuracy: 0.5500 - val_loss: 1.4604 - val_accuracy: 0.4467\n",
      "Epoch 28/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2733 - accuracy: 0.5486 - val_loss: 1.4670 - val_accuracy: 0.4400\n",
      "Epoch 29/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2551 - accuracy: 0.5514 - val_loss: 1.4466 - val_accuracy: 0.4533\n",
      "Epoch 30/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2398 - accuracy: 0.5714 - val_loss: 1.4341 - val_accuracy: 0.4600\n",
      "Epoch 31/500\n",
      "70/70 [==============================] - 0s 957us/step - loss: 1.2248 - accuracy: 0.5614 - val_loss: 1.4323 - val_accuracy: 0.4467\n",
      "Epoch 32/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2147 - accuracy: 0.5771 - val_loss: 1.4149 - val_accuracy: 0.4667\n",
      "Epoch 33/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2015 - accuracy: 0.5729 - val_loss: 1.4214 - val_accuracy: 0.4400\n",
      "Epoch 34/500\n",
      "70/70 [==============================] - 0s 986us/step - loss: 1.1892 - accuracy: 0.5986 - val_loss: 1.4147 - val_accuracy: 0.4633\n",
      "Epoch 35/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1770 - accuracy: 0.5843 - val_loss: 1.3880 - val_accuracy: 0.4833\n",
      "Epoch 36/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1661 - accuracy: 0.5857 - val_loss: 1.3823 - val_accuracy: 0.4667\n",
      "Epoch 37/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1538 - accuracy: 0.6000 - val_loss: 1.3831 - val_accuracy: 0.4733\n",
      "Epoch 38/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1423 - accuracy: 0.6057 - val_loss: 1.3822 - val_accuracy: 0.4700\n",
      "Epoch 39/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1347 - accuracy: 0.6086 - val_loss: 1.3644 - val_accuracy: 0.4800\n",
      "Epoch 40/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1256 - accuracy: 0.6229 - val_loss: 1.3692 - val_accuracy: 0.4767\n",
      "Epoch 41/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1128 - accuracy: 0.6200 - val_loss: 1.3718 - val_accuracy: 0.4800\n",
      "Epoch 42/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1043 - accuracy: 0.6157 - val_loss: 1.3560 - val_accuracy: 0.4733\n",
      "Epoch 43/500\n",
      "70/70 [==============================] - 0s 957us/step - loss: 1.0938 - accuracy: 0.6300 - val_loss: 1.3545 - val_accuracy: 0.4900\n",
      "Epoch 44/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0860 - accuracy: 0.6271 - val_loss: 1.3503 - val_accuracy: 0.4867\n",
      "Epoch 45/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0753 - accuracy: 0.6229 - val_loss: 1.3549 - val_accuracy: 0.4733\n",
      "Epoch 46/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0689 - accuracy: 0.6214 - val_loss: 1.3487 - val_accuracy: 0.4733\n",
      "Epoch 47/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0613 - accuracy: 0.6500 - val_loss: 1.3417 - val_accuracy: 0.4900\n",
      "Epoch 48/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0531 - accuracy: 0.6429 - val_loss: 1.3422 - val_accuracy: 0.4800\n",
      "Epoch 49/500\n",
      "70/70 [==============================] - 0s 971us/step - loss: 1.0444 - accuracy: 0.6443 - val_loss: 1.3462 - val_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0396 - accuracy: 0.6414 - val_loss: 1.3447 - val_accuracy: 0.4867\n",
      "Epoch 51/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0311 - accuracy: 0.6429 - val_loss: 1.3434 - val_accuracy: 0.4767\n",
      "Epoch 52/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0233 - accuracy: 0.6529 - val_loss: 1.3417 - val_accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs=500,batch_size=10,\n",
    "                 validation_data=(X_val,Y_val),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 원핫인코딩 (one-hot encoding) 처리\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "x_train = x_train[42000:]\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=3)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__모델 저장__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sample_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('sample_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-44-78f321797f65>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "True : 0, Predict : 0\n",
      "True : 1, Predict : 1\n",
      "True : 6, Predict : 1\n",
      "True : 6, Predict : 1\n",
      "True : 4, Predict : 4\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN을 이용한 수열 생성  \n",
    "ex) [0.0 -> 0.1 -> 0.2 -> 0.3] ==> ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, LSTM, Embedding, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1feb559ec88>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequential([SimpleRNN(units=1 , activation='tanh' , \n",
    "                      return_sequences=False , return_state=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. ]\n",
      "  [0.1]\n",
      "  [0.2]\n",
      "  [0.3]]\n",
      "\n",
      " [[0.1]\n",
      "  [0.2]\n",
      "  [0.3]\n",
      "  [0.4]]\n",
      "\n",
      " [[0.2]\n",
      "  [0.3]\n",
      "  [0.4]\n",
      "  [0.5]]\n",
      "\n",
      " [[0.3]\n",
      "  [0.4]\n",
      "  [0.5]\n",
      "  [0.6]]\n",
      "\n",
      " [[0.4]\n",
      "  [0.5]\n",
      "  [0.6]\n",
      "  [0.7]]\n",
      "\n",
      " [[0.5]\n",
      "  [0.6]\n",
      "  [0.7]\n",
      "  [0.8]]]\n",
      "[0.4 0.5 0.6 0.7 0.8 0.9]\n"
     ]
    }
   ],
   "source": [
    "X = [] \n",
    "Y = [] \n",
    "for i in range(6): \n",
    "    lst = list(range(i,i+4)) \n",
    "    X.append(list(map(lambda c: [c/10], lst))) \n",
    "    Y.append((i+4)/10) \n",
    "X = np.array(X) \n",
    "Y = np.array(Y) \n",
    "print(X)  #6,4,1\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([SimpleRNN(units=10 , \n",
    "                      activation='tanh' , \n",
    "                      input_shape=[4,1],\n",
    "                      return_sequences=False),\n",
    "                   Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0064\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0033\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0028\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0022\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0015\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0014\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0018\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0018\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0013\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0014\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0014\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0013\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.0012\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0012\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0012\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0012\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0010\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0010\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.9705e-04\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.9051e-04\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8470e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.7952e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7460e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6953e-04\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6404e-04\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5813e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5197e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 9.4584e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.3998e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3443e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2911e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2384e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1845e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1286e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0714e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.0138e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.9571e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.9020e-04\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.8481e-04\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7949e-04\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7415e-04\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6874e-04\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.6326e-04\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5776e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.5230e-04\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4691e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4159e-04\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36253026],\n",
       "       [0.51166   ],\n",
       "       [0.6330913 ],\n",
       "       [0.728557  ],\n",
       "       [0.8027463 ],\n",
       "       [0.86050427]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = np.array([[[11.0],[11.1],[11.2],[11.3]]])\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62080103]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 기반 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"인공지능을 공부하면서 코딩을 하고 있다\\n\n",
    "파이썬 코딩을 배우고 익혔다\\n\n",
    "딥러닝을 배우고 코딩을 하고 있다\\n\n",
    "파이썬 기반에서 판다스를 배우고 코딩을 했다\\n\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('인공지능을', 1),\n",
       "             ('공부하면서', 1),\n",
       "             ('코딩을', 4),\n",
       "             ('하고', 2),\n",
       "             ('있다', 2),\n",
       "             ('파이썬', 2),\n",
       "             ('배우고', 3),\n",
       "             ('익혔다', 1),\n",
       "             ('딥러닝을', 1),\n",
       "             ('기반에서', 1),\n",
       "             ('판다스를', 1),\n",
       "             ('했다', 1)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ =\"\"\"인공지능을 공부하면서 코딩을 하고 있다\\n\n",
    "파이썬 코딩을 배우고 익혔다\\n\n",
    "딥러닝을 배우고 코딩을 하고 있다\\n\n",
    "파이썬 기반에서 판다스를 배우고 코딩을 했다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 1, 3, 4]\n",
      "[]\n",
      "[5, 1, 2, 8]\n",
      "[]\n",
      "[9, 2, 1, 3, 4]\n",
      "[]\n",
      "[5, 10, 11, 2, 1, 12]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text_.split('\\n'): \n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    print(encoded)\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7],\n",
       " [6, 7, 1],\n",
       " [6, 7, 1, 3],\n",
       " [6, 7, 1, 3, 4],\n",
       " [5, 1],\n",
       " [5, 1, 2],\n",
       " [5, 1, 2, 8],\n",
       " [9, 2],\n",
       " [9, 2, 1],\n",
       " [9, 2, 1, 3],\n",
       " [9, 2, 1, 3, 4],\n",
       " [5, 10],\n",
       " [5, 10, 11],\n",
       " [5, 10, 11, 2],\n",
       " [5, 10, 11, 2, 1],\n",
       " [5, 10, 11, 2, 1, 12]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "\n",
    "max_len = len(max(sequences,key=len))\n",
    "sequences = pad_sequences(sequences,max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]\n",
    "Y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y,num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Embedding : 고차원의 텍스트 데이터를 저차원으로 축소__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Embedding(vocab_size,10,input_length=max_len-1))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8750\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8750\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2856 - accuracy: 0.8750\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8750\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8750\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2793 - accuracy: 0.8750\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8750\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8750\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8750\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2694 - accuracy: 0.8750\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8750\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8750\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2637 - accuracy: 0.9375\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2619 - accuracy: 0.9375\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9375\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.9375\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.9375\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2548 - accuracy: 0.9375\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2531 - accuracy: 0.9375\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2514 - accuracy: 0.9375\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2497 - accuracy: 0.9375\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2480 - accuracy: 0.9375\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9375\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9375\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2432 - accuracy: 0.9375\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9375\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2400 - accuracy: 0.9375\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9375\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2370 - accuracy: 0.9375\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9375\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2340 - accuracy: 0.9375\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9375\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9375\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9375\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9375\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2267 - accuracy: 0.9375\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9375\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9375\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9375\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2212 - accuracy: 0.9375\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2199 - accuracy: 0.9375\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2185 - accuracy: 0.9375\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9375\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2159 - accuracy: 0.9375\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2146 - accuracy: 0.9375\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2133 - accuracy: 0.9375\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9375\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9375\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.9375\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9375\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2071 - accuracy: 0.9375\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.2059 - accuracy: 0.9375\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2047 - accuracy: 0.9375\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9375\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9375\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2011 - accuracy: 0.9375\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9375\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1988 - accuracy: 0.9375\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1977 - accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1965 - accuracy: 0.9375\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9375\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9375\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9375\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9375\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1910 - accuracy: 0.9375\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9375\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1889 - accuracy: 0.9375\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9375\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1868 - accuracy: 0.9375\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1857 - accuracy: 0.9375\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1847 - accuracy: 0.9375\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1837 - accuracy: 0.9375\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9375\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9375\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9375\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1787 - accuracy: 0.9375\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9375\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1768 - accuracy: 0.9375\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1758 - accuracy: 0.9375\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9375\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1740 - accuracy: 0.9375\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1731 - accuracy: 0.9375\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9375\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9375\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9375\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9375\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9375\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1677 - accuracy: 0.9375\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9375\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1660 - accuracy: 0.9375\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1651 - accuracy: 0.9375\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9375\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1634 - accuracy: 0.9375\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1626 - accuracy: 0.9375\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1618 - accuracy: 0.9375\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1610 - accuracy: 0.9375\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9375\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.9375\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1586 - accuracy: 0.9375\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1579 - accuracy: 0.9375\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9375\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9375\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1556 - accuracy: 0.9375\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9375\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9375\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1534 - accuracy: 0.9375\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1527 - accuracy: 0.9375\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9375\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1513 - accuracy: 0.9375\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9375\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1499 - accuracy: 0.9375\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1493 - accuracy: 0.9375\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9375\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9375\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1473 - accuracy: 0.9375\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9375\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1460 - accuracy: 0.9375\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9375\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1448 - accuracy: 0.9375\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1442 - accuracy: 0.9375\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9375\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9375\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9375\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1418 - accuracy: 0.9375\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1412 - accuracy: 0.9375\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9375\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9375\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1395 - accuracy: 0.9375\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9375\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9375\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1379 - accuracy: 0.9375\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1374 - accuracy: 0.9375\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1369 - accuracy: 0.9375\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9375\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9375\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1354 - accuracy: 0.9375\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9375\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9375\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9375\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1334 - accuracy: 0.9375\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9375\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9375\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1321 - accuracy: 0.9375\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9375\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1312 - accuracy: 0.9375\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9375\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9375\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1299 - accuracy: 0.9375\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9375\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1291 - accuracy: 0.9375\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1287 - accuracy: 0.9375\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9375\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1279 - accuracy: 0.9375\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1275 - accuracy: 0.9375\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1271 - accuracy: 0.9375\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1267 - accuracy: 0.9375\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9375\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9375\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1256 - accuracy: 0.9375\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1252 - accuracy: 0.9375\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9375\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9375\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 0.1242 - accuracy: 0.9375\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9375\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9375\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1232 - accuracy: 0.9375\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9375\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1225 - accuracy: 0.9375\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1222 - accuracy: 0.9375\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9375\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1216 - accuracy: 0.9375\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1213 - accuracy: 0.9375\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9375\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1207 - accuracy: 0.9375\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1204 - accuracy: 0.9375\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9375\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9375\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9375\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9375\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1189 - accuracy: 0.9375\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1187 - accuracy: 0.9375\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1184 - accuracy: 0.9375\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9375\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1179 - accuracy: 0.9375\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1176 - accuracy: 0.9375\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9375\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1171 - accuracy: 0.9375\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9375\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.9375\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9375\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1161 - accuracy: 0.9375\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9375\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1156 - accuracy: 0.9375\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1154 - accuracy: 0.9375\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1152 - accuracy: 0.9375\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1150 - accuracy: 0.9375\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1147 - accuracy: 0.9375\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2863d46c988>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['인공지능을','공부하면서'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(obj,tokenizer,current_word,num_out):\n",
    "    \n",
    "    init_word = current_word # 문장의 시작단어 저장\n",
    "    sentence=''\n",
    "    \n",
    "    for _ in range(num_out):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0] # 단어의 인덱스\n",
    "        encoded = pad_sequences([encoded],maxlen=5,padding='pre')\n",
    "        \n",
    "        result_idx = obj.predict_classes(encoded)[0]\n",
    "        result_word = tokenizer.index_word[result_idx]\n",
    "        sentence+=' '+result_word\n",
    "    \n",
    "    sentence=init_word+sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능을 공부하면서 공부하면서 공부하면서 공부하면서\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model,t,'인공지능을',4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(encoded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
